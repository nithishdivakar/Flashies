\section{Markov Chains}
\parindent=0pt
\begin{slide}[Markov Chains]

\noindent{}Let $X_0, X_1, \ldots, X_n, \ldots $ be an evolution of a random vriable over time.
The process of evolution is said to have \textbf{markov property} if
\begin{shaded}
\begin{align*}
P(X_{n+1} =j|X_n=i,X_{n-1} = i_{n-1},\ldots, X_0 = i_0)
&= P(X_{n+1} = j| X_n=i) 
\\
&=q_{ij} \text{ transition probability}
\end{align*}
\end{shaded}

$i$, $j$, $i_{\cdot}$ etc are states and the matrix $Q = (q_{ij})$ defines the probability of transitioning from one state to another. $Q$ is called transition matrix. The rows of $Q$ sum to $1$ and all entries are positive.
\end{slide}
\begin{slidemaximus}
\begin{multicols}{2}
Suppose at time $n$,  $X_n$ has distirbution $\vec{S}$ (row vector, Probability of being in state $i$). 

\begin{align*}
P&(X_{n+1} = j) 
\\
&= \sum _{i} P(X_{n+1} = j| X_n=i)P(X_n = i)
\\
&= \sum s_iq_{ij} 
\\
&=\text{ is the jth entry of }\vec{S}Q
\end{align*}

$\vec{S}Q$ is distribution at $n+1$\\
$\vec{S}Q^2$ is distribution at $n+2$ and so on...

\begin{align*}
\intertext{Now,} 
P&(X_{n+2}=j|X_n=i) 
\\
&= \sum_k P(X_{n+2}|X_{n+1}=k,X_n=i)P(X_{n+1}=k,X_n=i)
\\
&= \sum_k P(X_{n+2}|X_{n+1}=k)P(X_{n+1}=k,X_n=i)
\\
&= \sum_k q_{kj}q_{ik}
\\
&= (i,j)^{th} \text{ entry of } Q^2
\\
P&(X_{n+m}|X_n=i) = Q^m
\end{align*}
\end{multicols}
%%%
%%% Check this sentence.
%%%
\centering
The transition matrix alone give all informatin about states
\end{slidemaximus}

\begin{slide}[Stationary Distribution]
$\vec{S}$  is stationary for the chain if $\vec{S}Q = \vec{S}$.


\end{slide}
\begin{slide}[Reversible Mrkov Chains]
\begin{description}
  \item[Defn] Markov chain w.r.to transition matrix $Q =(Q_{ij})$ is reversible if there is  probability vector $\vec{s}$ such that 
$$s_iq_{ij} = s_jq_{ji}$$ for all states $i,j$. In such case, $\vec{s}$ is the stationary distribution.
\end{description}
Proof: $\sum_is_iq_{ij} = \sum_is_jq_{ji} = s_j\sum_iq_{ji} = s_j$

\end{slide}
