\begin{slide}[Basics]
  $$x:~patterns \qquad y:~labels \qquad \Theta:~parameters$$
  \begin{multicols}{2}
    \subsubsection*{Supervised learning}
      $$P(y|x;\theta)$$
      predict label given a pattern.
    \subsubsection*{Unsupervised learning}
      $$P(x,y |\theta) \qquad or \qquad P(x;\theta)  $$
      learn the p.d.f of the data
  \end{multicols}
  reinforcement learning, recommender systems
\end{slide}
\begin{slide}[Supervised Learning]
We are given a finite number of labeled examples 
$$S=((x_1,y_1),\ldots,(x_m,y_m))\in(X\times Y)^m$$
Where $X$ is an instance space containing objects for which predictions are to be made and $Y$ is label space from which labels are drawn.
\par
The aim of supervised learning algorithms is to learn a mapping(model)
$$h_S:X\to\hat{Y}$$ which correctly predicts the labels given a new data in $X$. \footnote{Often $Y=\hat{Y}$. But not always.}
Performance of a model is measured via a loss function of the form $\ell:Y\times\hat{Y}\to \mathbb{R}^+$
\footnotetext{[Ref:] E0:270 lecture notes}
\end{slide}



\begin{slide}[Unsupervised Learning]
	We are given instances of some space $X$ and the goal is to discover some pattern or structure in data. Typically, we are given training set
	$$S=(x_1,\ldots,x_m)\in X^m$$
	and we assume it is drawn from some unknown probability distribution in $X$. The goal then is to estimate property of this distribution.
	\begin{description}
		\item[Density estimation] Estimate probability distribution assumed to be generating data in $S$
		\item[Clustering] identify natural groups or clusters in the distribution generating $S$
	\end{description}
\end{slide}

\begin{slide}[Gradient Descent]
  \begin{description}
    \item[defn.]Gradient Descent is a first order optimization algorithm. 
    \item[Intuition] Direction of gradient of a function is the direction of maximum increase. So moving opposite to it will decrease the function.
  \end{description}
  $$x_{n+1} = x_n - \explain{\alpha_n}{learning~rate} \nabla F(x_n)$$

\end{slide}
\begin{slide}[Stochastic Gradient Descent]
  If the objective function is of the form $L(\theta) = \sum_iL_i(\theta)$ and we need to compute $\mathop{\mathrm{arg\,min}}_\theta L(\theta)$.
  \footnotetext{This type of objective function is motivated by loss of the model is the sum of losses of its performance on each training example}
  
  
  The normal gradient descent would do
  $$\theta \gets \theta - \alpha \nabla L(\theta) = \theta-\alpha\sum_i\nabla L_i(\theta)$$
  but in SGD, the true gradient of $L(\theta)$ is approximated by a gradient of a single example.
  $$\theta \gets \theta - \alpha\nabla L_i(\theta)$$

  SGD with momentum
  \begin{align*}
   \grad \theta &= \alpha \nabla L_i(\theta) + p \explain{\grad \theta}{previous update}
   \\
   \theta&\gets \theta -\grad \theta
  \end{align*}
\end{slide}
